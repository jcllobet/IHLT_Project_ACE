{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## Students: Nafis Banirazi & Jan Carbonell\n",
    "### Lab Objective:\n",
    "The Objectives of this project are the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intial set of imports\n",
    "import nltk\n",
    "import numpy\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "#variable initialization and instantiation\n",
    "d = {}\n",
    "j = [0]\n",
    "tests = []\n",
    "corpus = []\n",
    "tests = []\n",
    "golden_std = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read all pairs of sentences of the train and test set\n",
    "We proceed to open and read the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sentences(filename):\n",
    "    sentence_pair_array = []\n",
    "    for line in open(filename, encoding=\"UTF8\").readlines():\n",
    "        sentence_pair_array.append([s.strip() for s in line.split(\"\\t\")])\n",
    "    return sentence_pair_array\n",
    "\n",
    "train_input = text_to_sentences('../00_data/train/STS.input.MSRpar.txt')\n",
    "test_input = text_to_sentences('../00_data/test-gold/STS.input.MSRpar.txt')\n",
    "train_classes = open('../00_data/train/STS.gs.MSRpar.txt', encoding=\"utf-8-sig\").readlines()\n",
    "test_classes = open('../00_data/test-gold/STS.gs.MSRpar.txt', encoding=\"UTF8\").readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Noisy entities removal functions\n",
    "### Stopwords, URL's, Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the punctuation and lowering the case of a string\n",
    "def remove_punctuation(line):\n",
    "    return line.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word normalization\n",
    "### Tokenization, Lemmatization, Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the words from the sentence\n",
    "def words_from_sent(sent):\n",
    "    # tokenized\n",
    "    tokenized = nltk.word_tokenize(sent)\n",
    "    # remove stopwords and return\n",
    "    return [word for word in tokenized if word not in nltk.corpus.stopwords.words('english')]\n",
    "\n",
    "# convert words to tokens\n",
    "def tokens_from_words(words):\n",
    "    return pos_tag(words)\n",
    "\n",
    "# Function to get wordnet pos code\n",
    "def wordnet_pos_code(tag):\n",
    "    if tag.startswith('NN'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('VB'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('JJ'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('RB'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Tokens to lemmas using wordnet lemmatizer    \n",
    "def tokens_to_lemmas(tokens):\n",
    "    return list(map(token_to_lemmas, tokens))\n",
    "\n",
    "def token_to_lemmas(token):    \n",
    "    pos = wordnet_pos_code(token[1])\n",
    "    if pos:\n",
    "        return WordNetLemmatizer().lemmatize(token[0], pos=pos)\n",
    "    return token[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word Standarization\n",
    "### Regular Expression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation imports\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def count(g,s):\n",
    "    TP = TN = FP = FN = 0\n",
    "    for i in range(0,len(g)):\n",
    "        if (g[i]==s[i] and s[i]==1): TP+=1\n",
    "        if (g[i]==s[i] and s[i]==0): TN+=1\n",
    "        if (g[i]!=s[i] and s[i]==1): FP+=1\n",
    "        if (g[i]!=s[i] and s[i]==0): FN+=1\n",
    "    return [TP,TN,FP,FN]\n",
    "\n",
    "def MSRP_eval(gs, sys):\n",
    "    [TP,TN,FP,FN] = count(gs,sys)\n",
    "    acc = (TP+TN)/float(TP+TN+FP+FN) # ACCURACY\n",
    "    reject = TN/float(TN+FP) # precision on negative SPECIFICITY\n",
    "    accept = TP/float(TP+FN) # precision on positive SENSITIVITY\n",
    "    print(\"acc=\",acc,\" reject=\",reject,\" accept=\",accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Testing\n",
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Results\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-306fe5e189ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mregression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mMSRP_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    First Paraphrase detector approach, jaccard distance of lemmas    \n",
    "'''\n",
    "def lemma_jaccard(sent_0, sent_1):\n",
    "    print('.', end='')\n",
    "    sent_0, sent_1 = remove_punctuation(sent_0.lower()), remove_punctuation(sent_1.lower())\n",
    "    words_0, words_1 = words_from_sent(sent_0), words_from_sent(sent_1)\n",
    "    tokens_0, tokens_1 = tokens_from_words(words_0), tokens_from_words(words_1)\n",
    "    lemmas_0, lemmas_1 = tokens_to_lemmas(tokens_0), tokens_to_lemmas(tokens_1)\n",
    "    return jaccard_distance(set(lemmas_0), set(lemmas_1))\n",
    "\n",
    "print('Training')\n",
    "X_train = [lemma_jaccard(data[0], data[1]) for data in train_input]\n",
    "y_train = [float(line.strip()) for line in train_classes]\n",
    "print('Testing')\n",
    "X_test = [lemma_jaccard(data[0], data[1])for data in test_input]\n",
    "y_test = [float(line.strip()) for line in test_classes]\n",
    "print('Results')\n",
    "regression = LogisticRegression()\n",
    "regression.fit(np.array(X_train).reshape(-1,1), y_train)\n",
    "prediction = regression.predict(np.array(X_test).reshape(-1,1))\n",
    "MSRP_eval(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply Lesk’s algorithm to the words in the sentences.\n",
    "In this step, we must first tokenize the sentences. \n",
    "We then apply pos_tag to determine the type of each word in the sentence; and apply lesk algorithm.\n",
    "Then we take the sets to unique values and delete None element.\n",
    "Finally, we compute the jaccard similarity as 1 - jaccard distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesking_sentence(pos_tagged_sentence):\n",
    "    \"\"\"\n",
    "    Returns a sentence as the given sentece using lesker algorithms.\n",
    "    The input sentence must be a pos_tagged sentence (e.g. [('The', 'DN'),\n",
    "    ('sun', 'NN')]).\n",
    "    \"\"\"\n",
    "    sentence = [i[0] for i in pos_tagged_sentence]\n",
    "    result = []\n",
    "    \n",
    "    none_type_objects = []\n",
    "    for word, tag in pos_tagged_sentence:\n",
    "        # 'NoneType' object has no attribute 'name'\n",
    "        try:\n",
    "            if tag.startswith('N'):\n",
    "                result.append(lesk(sentence, word, wn.NOUN).name())\n",
    "            #if word is a verb\n",
    "            elif tag.startswith('V'):\n",
    "                result.append(lesk(sentence, word, wn.VERB).name())\n",
    "            #if word is an adjective\n",
    "            elif tag.startswith('J'):\n",
    "                result.append(lesk(sentence, word, wn.ADJ).name())\n",
    "            #if word is a verb\n",
    "            elif tag.startswith('R'):\n",
    "                result.append(lesk(sentence, word, wn.ADV).name())\n",
    "            else:\n",
    "                result.append(word)\n",
    "        except:\n",
    "            print('EXEPTION ERROR:', word, tag)\n",
    "            none_type_objects.append([word, tag, lesk(sentence, word, wn.NOUN)])\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in d:\n",
    "    \n",
    "    # Tokenizing\n",
    "    sents = [nltk.word_tokenize(s) for s in d[key]];    \n",
    "    \n",
    "    w1 = sents[0]\n",
    "    w2 = sents[1]\n",
    "\n",
    "    # Determining the category of words\n",
    "    wordtype1 = pos_tag(w1)    \n",
    "    wordtype2 = pos_tag(w2)\n",
    "\n",
    "    # As Lesk's algorithm works with synsets\n",
    "    # Not every word will be accepted. Just nouns, verbs, adjectives and adverbs\n",
    "    #determining the definition of words\n",
    "    lesk1 = lesking_sentence(wordtype1)\n",
    "    print('Post_Lesked_Sentence: ', lesk1, '\\n')\n",
    "    lesk2 = lesking_sentence(wordtype2)\n",
    "    print('Post_Lesked_Sentence: ', lesk2, '\\n')\n",
    "\n",
    "    # Removing duplicates\n",
    "    set1 = set(lesk1)\n",
    "    set2 = set(lesk2)\n",
    "    \n",
    "    #computing jaccard similarity\n",
    "    jaccard_similarity = 1 - jaccard_distance(set1, set2)\n",
    "    tests.append(round(jaccard_similarity,3))\n",
    "print(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute their similarities via the Jaccard coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done previously within the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare the results with those in session 2 (document) and 3 (morphology) in which words and lemmas were considered.\n",
    "The gold standard results would be 5,4,3,2,1,0.\n",
    "\n",
    "\n",
    "In session 2 we got the following results:\n",
    "\n",
    "* *'id1': 0.308* --> 1.54\n",
    "* *'id2': 0.263* --> 1.31\n",
    "* *'id3': 0.467* --> 2.34\n",
    "* *'id4': 0.455* --> 2.27\n",
    "* *'id5': 0.231* --> 1.15\n",
    "* *'id6': 0.138* --> 0.69\n",
    "\n",
    "In session 3, using lemmas similarity, we obtained:\n",
    "* *'id1': 0.333* --> 1.67\n",
    "* *'id2': 0.412* --> 2.06\n",
    "* *'id3': 0.571* --> 2.86\n",
    "* *'id4': 0.333* --> 1.67\n",
    "* *'id5': 0.167* --> 0.84\n",
    "* *'id6': 0.138* --> 0.69\n",
    "\n",
    "And our current result is:\n",
    "* *'id1': 0.333* --> 1.67\n",
    "* *'id2': 0.375* --> 1.88\n",
    "* *'id3': 0.571* --> 2.86\n",
    "* *'id4': 0.273* --> 1.36\n",
    "* *'id5': 0.167* --> 0.84\n",
    "* *'id6': 0.103* --> 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare the results with gold standard by giving the pearson correlation between them.\n",
    "And now, we open the Golden Standard file and calculate the perason correlation with lesk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAREFUL WITH THE STS.gs FILE. \n",
    "\n",
    "# Golden Records file\n",
    "golden_file = open('../00_data/test/STS.gs.MSRpar.txt','r')\n",
    "\n",
    "for line in golden_file:\n",
    "    line = line.strip().split(\"\\t\")\n",
    "    golden_std.append(int(line[1]))\n",
    "\n",
    "a = pearsonr(tests, golden_std)[0]\n",
    "print('Pearson correlation with lesk:', round(a,3))\n",
    "print(golden_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the results with those in session 2 (document) and 3 (morphology) in which words and lemmas were considered:\n",
    "- Pearson correlation without lemmatization: 0.396\n",
    "- Pearson correlation with lemmatization: 0.578\n",
    "- Pearson correlation with lesk: 0.668\n",
    "\n",
    "This may also be to an improvement in our way of splitting the words and sorting the sentences that we have implemented in this lab. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
