{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Exercise - Session 5\n",
    "\n",
    "### Students: Nafis Banirazi & Jan Carbonell\n",
    "\n",
    "### Lab Objective:\n",
    "The Objective of this lab is to categorize the given pairs, print their most frequent WordNet synset, their corresponding least common subsumer (LCS) and their similarity using the following functions:\n",
    "\n",
    "- Path Similarity\n",
    "- Leacock-Chodorow Similarity\n",
    "- Wu-Palmer Similarity\n",
    "- Lin Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports. Could also be done in the PC\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "#additional set of imports\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "\n",
    "#given set of pairs\n",
    "pairs = [('the', 'DT'), ('man', 'NN'), ('swim', 'VB'), \\\n",
    "         ('with', 'PR'), ('a', 'DT'), ('girl', 'NN'), \\\n",
    "         ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), \\\n",
    "         ('whilst', 'PR'), ('the', 'DT'), ('woman', 'NN'), \\\n",
    "         ('walk', 'VB')]\n",
    "n = {}\n",
    "v = {}\n",
    "aux = {}\n",
    "freq = []\n",
    "lcs = []\n",
    "definition = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Most frequent WordNet synsets\n",
    "\n",
    "Now, for each pair, we will search for their most frequent WordNet sysnset. In the documentation we can find that there are also adjectives and adverbs listed as options but are not used in this given set of pairs. Listing it as a reference: https://wordnet.princeton.edu/documentation/wn1wn\n",
    "\n",
    "For this given example, we will  select the words where the **POS tag** is **NN (noun)** or **VB (verb)**. We will then store the synsets of those words in two dictionaries *n and v* to preserve their link to the initial value.\n",
    "\n",
    "The **most frequent word** always **corresponds** to the **01 value of its synset**, so we can shorten the algorithm to speed up the process. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man Synset('man.n.01')\n",
      "girl Synset('girl.n.01')\n",
      "boy Synset('male_child.n.01')\n",
      "woman Synset('woman.n.01')\n",
      "swim Synset('swim.v.01')\n",
      "walk Synset('walk.v.01')\n"
     ]
    }
   ],
   "source": [
    "for e in pairs:\n",
    "    if e[0] not in n and e[0] not in v:\n",
    "        if e[1] == 'NN':\n",
    "            n[e[0]] = wn.synset(e[0]+'.n.01')\n",
    "        elif e[1] == 'VB':\n",
    "            v[e[0]] = wn.synset(e[0]+'.v.01')\n",
    "            \n",
    "#verification that it is properly stored\n",
    "for keys,values in n.items():\n",
    "    print(keys, values)\n",
    "    \n",
    "for keys,values in v.items():\n",
    "    print(keys, values)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Least Common Subsumer (LCS)\n",
    "\n",
    "For each of the pairs that was found to be on WordNet, we now get their corresponding least commmon subsumer. That is the most specific common ancestor (hypernym) of two concepts found in a given ontology. For example, the LCS of moose and kangaroo in WordNet is mammal.\n",
    "\n",
    "In order to better process the information in one batch, we add the values to a list, indicating if they are a **'noun'** or a **'verb'** and we find their lowest common hypernyms if they belong to the same class -since noun and verbs do not share Hypernyms between eachother-.\n",
    "<i>http://www.nltk.org/howto/wordnet_lch.html</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in n:\n",
    "    freq.append([key,n[key], 'noun'])\n",
    "\n",
    "for key in v:\n",
    "    freq.append([key,v[key], 'verb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in freq:\n",
    "    row = []\n",
    "    for alt in freq:\n",
    "        if key[2] == alt [2]:\n",
    "            row.append(key[1].lowest_common_hypernyms(alt[1]))\n",
    "        else:\n",
    "            row.append(0)\n",
    "    lcs.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the data, which we label with the first value of each element of the dictionary (name of the pair). Within the documentation,we can find that the LCS between the same words is that very same word, we replaced the empty value with a 0 to further increase its visualization and transform all the matrix to a number. *This will prove useful later in the following algorithms*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>swim</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>[Synset('man.n.01')]</td>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('male.n.02')]</td>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('girl.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>[Synset('male.n.02')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('male_child.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Synset('swim.v.01')]</td>\n",
       "      <td>[Synset('travel.v.01')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Synset('travel.v.01')]</td>\n",
       "      <td>[Synset('walk.v.01')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          man                     girl  \\\n",
       "man      [Synset('man.n.01')]   [Synset('adult.n.01')]   \n",
       "girl   [Synset('adult.n.01')]    [Synset('girl.n.01')]   \n",
       "boy     [Synset('male.n.02')]  [Synset('person.n.01')]   \n",
       "woman  [Synset('adult.n.01')]   [Synset('woman.n.01')]   \n",
       "swim                        0                        0   \n",
       "walk                        0                        0   \n",
       "\n",
       "                               boy                    woman  \\\n",
       "man          [Synset('male.n.02')]   [Synset('adult.n.01')]   \n",
       "girl       [Synset('person.n.01')]   [Synset('woman.n.01')]   \n",
       "boy    [Synset('male_child.n.01')]  [Synset('person.n.01')]   \n",
       "woman      [Synset('person.n.01')]   [Synset('woman.n.01')]   \n",
       "swim                             0                        0   \n",
       "walk                             0                        0   \n",
       "\n",
       "                          swim                     walk  \n",
       "man                          0                        0  \n",
       "girl                         0                        0  \n",
       "boy                          0                        0  \n",
       "woman                        0                        0  \n",
       "swim     [Synset('swim.v.01')]  [Synset('travel.v.01')]  \n",
       "walk   [Synset('travel.v.01')]    [Synset('walk.v.01')]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs_np = np.array(lcs)\n",
    "label = [i[0] for i in freq]\n",
    "pd.DataFrame(lcs_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe from the results, the similarities make semantical sense. \n",
    "- Man and girl are connected by adulthood. Same with man and woman\n",
    "- Girl and boy are connected by person\n",
    "- Interestingly enough, Woman and boy are connected by person despite of Man and girl being connected by adulthood. \n",
    "\n",
    "### 3. Similarity Value\n",
    "\n",
    "We now proceed with the implementation of the algorithm. We also initiate an empty list to store the results for each algorithm and initialize the values and minimum results. In order to speed the calculations, we initiate the maximum value of each algorithm outside the loop.\n",
    "\n",
    "The algorithm calculates the results of the 4 algorithms simultaneously, updates the minimum when needed and rounds the value to the nearest three decimals. \n",
    "\n",
    "Regarding the Lin Similarity, we also need to compute the Information Content (IC) value, which loads an IC file from the wordnet_ic corpus.\n",
    "\n",
    "We also initiate the sum values of the matrix, which will be useful to discuss their effectiveness later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 0.25, 0.333, 0.333, 0, 0], [0.25, 1.0, 0.167, 0.5, 0, 0], [0.333, 0.167, 1.0, 0.2, 0, 0], [0.333, 0.5, 0.2, 1.0, 0, 0], [0, 0, 0, 0, 1.0, 0.333], [0, 0, 0, 0, 0.333, 1.0]]\n",
      "10.232\n",
      "\n",
      "\n",
      "[[3.638, 2.251, 2.539, 2.539, 0, 0], [2.251, 3.638, 1.846, 2.944, 0, 0], [2.539, 1.846, 3.638, 2.028, 0, 0], [2.539, 2.944, 2.028, 3.638, 0, 0], [0, 0, 0, 0, 3.258, 2.159], [0, 0, 0, 0, 2.159, 3.258]]\n",
      "53.68\n",
      "\n",
      "\n",
      "[[1.0, 0.632, 0.667, 0.667, 0, 0], [0.632, 1.0, 0.632, 0.632, 0, 0], [0.667, 0.632, 1.0, 0.667, 0, 0], [0.667, 0.947, 0.667, 1.0, 0, 0], [0, 0, 0, 0, 1.0, 0.333], [0, 0, 0, 0, 0.333, 1.0]]\n",
      "14.774999999999999\n",
      "\n",
      "\n",
      "[[1.0, 0.702, 0.798, 0.802, 0, 0], [0.702, 1.0, 0.274, 0.882, 0, 0], [0.798, 0.274, 1.0, 0.308, 0, 0], [0.802, 0.882, 0.308, 1.0, 0, 0], [0, 0, 0, 0, 1.0, 0.466], [0, 0, 0, 0, 0.466, 1.0]]\n",
      "14.463999999999997\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "semcor_ic = wordnet_ic.ic('ic-semcor.dat')\n",
    "\n",
    "path, lch, wup, lin = [], [], [], []\n",
    "v1, v2, v3, v4 = 0, 0, 0, 0\n",
    "min1, min2, min3, min4 = 10, 10, 10, 10\n",
    "\n",
    "sum1, sum2, sum3, sum4 = 0, 0, 0, 0\n",
    "\n",
    "#calculating max value of the algorithms outside the loop to preserve them\n",
    "a = wn.synset('dog.n.01')\n",
    "max1 = wn.lch_similarity(a, a)\n",
    "max2 = wn.lch_similarity(a, a)\n",
    "max3 = wn.wup_similarity(a, a)\n",
    "max4 = a.lin_similarity(a, semcor_ic)\n",
    "\n",
    "for key in freq:\n",
    "    \n",
    "    #initializing the rows of the matrices\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "    row3 = []\n",
    "    row4 = []\n",
    "    \n",
    "    for alt in freq:\n",
    "        # adding only if they belong to the same class 'noun' // 'verb'\n",
    "        if key[2] == alt[2]:\n",
    "            \n",
    "            # calculating the result of the algorithm\n",
    "            v1 = wn.path_similarity(key[1], alt[1])\n",
    "            v2 = wn.lch_similarity(key[1], alt[1])\n",
    "            v3 = wn.wup_similarity(key[1], alt[1])\n",
    "            v4 = key[1].lin_similarity(alt[1], semcor_ic)\n",
    "            \n",
    "            # tracking the minimum value in the matrix\n",
    "            if min1 > v1:\n",
    "                min1 = v1\n",
    "            elif min2 > v2:\n",
    "                min2 = v2\n",
    "            elif min3 > v3:\n",
    "                min3 = v3\n",
    "            elif min4 > v4:\n",
    "                min4 = v4\n",
    "                \n",
    "            #updating the total \"value\" of the matrix\n",
    "            sum1 += round(v1,3)\n",
    "            sum2 += round(v2,3)\n",
    "            sum3 += round(v3,3)\n",
    "            sum4 += round(v4,3)\n",
    "            \n",
    "            # rounding it and appending it to row\n",
    "            row1.append(round(v1, 3))\n",
    "            row2.append(round(v2, 3))\n",
    "            row3.append(round(v3, 3))\n",
    "            row4.append(round(v4, 3))\n",
    "            \n",
    "        else:\n",
    "            row1.append(0)\n",
    "            row2.append(0)\n",
    "            row3.append(0)\n",
    "            row4.append(0)\n",
    "    path.append(row1)\n",
    "    lch.append(row2)\n",
    "    wup.append(row3)\n",
    "    lin.append(row4)\n",
    "    \n",
    "#verification that it is properly stored    \n",
    "print(path)\n",
    "print(sum1)\n",
    "print('\\n')\n",
    "print(lch)\n",
    "print(sum2)\n",
    "print('\\n')\n",
    "print(wup)\n",
    "print(sum3)\n",
    "print('\\n')\n",
    "print(lin)\n",
    "print(sum4)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our rudimentary prints, the Leacock-Chodorow Similarity could use some normalization so that we can compare its efficiency to the other algorithms. Since we have already calculated the max and the previous loop is finished, the value of min is also final and we can apply the normalization as follows:\n",
    "\n",
    "<i>x' = (x - min_lch) / (max_lch - min_lch)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.356000000000002\n"
     ]
    }
   ],
   "source": [
    "#restart the value of the sum since we normalize\n",
    "sum2 = 0\n",
    "\n",
    "for row in range(len(lch)):\n",
    "    for e in range(len(lch[row])):\n",
    "        if lch[row][e] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            lch[row][e] = round((lch[row][e]-min2)/(max2-min2), 3)\n",
    "            sum2 += round(lch[row][e],3)\n",
    "            \n",
    "print(sum2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What similarity seems better?</b>\n",
    "\n",
    "First we proceed with each of the individual plots. One think to verify as we run to the matrices is the simetric value of the data. If the values diverge in each side of the diagonal, it already is a big indication of the inestability of the algorithm since the order of the products should not alter the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>swim</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.250</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         man   girl    boy  woman   swim   walk\n",
       "man    1.000  0.250  0.333  0.333  0.000  0.000\n",
       "girl   0.250  1.000  0.167  0.500  0.000  0.000\n",
       "boy    0.333  0.167  1.000  0.200  0.000  0.000\n",
       "woman  0.333  0.500  0.200  1.000  0.000  0.000\n",
       "swim   0.000  0.000  0.000  0.000  1.000  0.333\n",
       "walk   0.000  0.000  0.000  0.000  0.333  1.000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_np = np.array(path)\n",
    "pd.DataFrame(path_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to have in mind for the Leacock-Chodorow Similarity is that we have normalized it with the minimum value in our matrix, and not necessarly the min *possible* value.  This means that normalization could change if we were to calculate more broad results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>swim</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.226</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.387</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.102</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         man   girl    boy  woman   swim   walk\n",
       "man    1.000  0.226  0.387  0.387  0.000  0.000\n",
       "girl   0.226  1.000  0.000  0.613  0.000  0.000\n",
       "boy    0.387  0.000  1.000  0.102  0.000  0.000\n",
       "woman  0.387  0.613  0.102  1.000  0.000  0.000\n",
       "swim   0.000  0.000  0.000  0.000  0.788  0.175\n",
       "walk   0.000  0.000  0.000  0.000  0.175  0.788"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lch_np = np.array(lch)\n",
    "pd.DataFrame(lch_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>swim</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.632</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.632</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         man   girl    boy  woman   swim   walk\n",
       "man    1.000  0.632  0.667  0.667  0.000  0.000\n",
       "girl   0.632  1.000  0.632  0.632  0.000  0.000\n",
       "boy    0.667  0.632  1.000  0.667  0.000  0.000\n",
       "woman  0.667  0.947  0.667  1.000  0.000  0.000\n",
       "swim   0.000  0.000  0.000  0.000  1.000  0.333\n",
       "walk   0.000  0.000  0.000  0.000  0.333  1.000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_np = np.array(wup)\n",
    "pd.DataFrame(wup_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>swim</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.702</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.274</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.308</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.466</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         man   girl    boy  woman   swim   walk\n",
       "man    1.000  0.702  0.798  0.802  0.000  0.000\n",
       "girl   0.702  1.000  0.274  0.882  0.000  0.000\n",
       "boy    0.798  0.274  1.000  0.308  0.000  0.000\n",
       "woman  0.802  0.882  0.308  1.000  0.000  0.000\n",
       "swim   0.000  0.000  0.000  0.000  1.000  0.466\n",
       "walk   0.000  0.000  0.000  0.000  0.466  1.000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_np = np.array(lin)\n",
    "pd.DataFrame(lin_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed with the discussion of the efectiveness, we now have two tools, the sum of the elements of each of the matrix and the determinants. However, the determinants are not relevant in order to measure the effectiveness in the algorithm. They add and subtract values to calculate the space of the matrix and this is not what we want when evaluating the accuracy of each individual value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of values: 10.232\n",
      "determinant: 0.515\n",
      "difference in local max-min: 0.333 \n",
      "\n",
      "sum of values: 9.356\n",
      "determinant: 0.264\n",
      "difference in local max-min: 0.511 \n",
      "\n",
      "sum of values: 14.775\n",
      "determinant: 0.092\n",
      "difference in local max-min: 0.614 \n",
      "\n",
      "sum of values: 14.464\n",
      "determinant: 0.003\n",
      "difference in local max-min: 0.574\n"
     ]
    }
   ],
   "source": [
    "det_path = round(np.linalg.det(path_np),3)\n",
    "det_lch = round(np.linalg.det(lch_np),3)\n",
    "det_wup = round(np.linalg.det(wup_np),3)\n",
    "det_lin = round(np.linalg.det(lin_np),3)\n",
    "diff_path = 0.5 - min1\n",
    "diff_lch = 0.613 - 0.102\n",
    "diff_wup = 0.947 - min3\n",
    "diff_lin = 0.882 - min4\n",
    "\n",
    "# Path Similarity\n",
    "print('sum of values:', round(sum1,3))\n",
    "print('determinant:', det_path)  \n",
    "print('difference in local max-min:', round(diff_path,3), '\\n')\n",
    "\n",
    "# Leacock-Chodorow Similarity\n",
    "print('sum of values:', round(sum2,3))\n",
    "print('determinant:', det_lch)  \n",
    "print('difference in local max-min:', round(diff_lch,3), '\\n')\n",
    "\n",
    "# Wu-Palmer Similarity\n",
    "print('sum of values:', round(sum3,3))\n",
    "print('determinant:', det_wup)  \n",
    "print('difference in local max-min:', round(diff_wup,3), '\\n')\n",
    "      \n",
    "#Lin Similarity:\n",
    "print('sum of values:', round(sum4,3))\n",
    "print('determinant:', det_lin)  \n",
    "print('difference in local max-min:', round(diff_lin, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the sum of values, determinants and difference in local maximum and minimum, we must go back to the basics. In the leacock-similarity matrix, we can see that we have **mistakenly overnormalized the value of the comparison to equal verbs to 0.788**. This is likely due to the difference in the algorithm calculation and it is one of the inconveniences of the normalization. However, due to this very fact, the **normalized would be unsuitable if we were to have a bigger propotion of verbs** and thus, must be discarded for the general approach.\n",
    "\n",
    "Another thing that we pointed out before is that paths should be the same with identical **switched** starting conditions. As we can see in Wu-Palmer, this is not the case and must also be discarded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n",
      "0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('woman.n.01').wup_similarity(wn.synset('girl.n.01')))\n",
    "print(wn.synset('girl.n.01').wup_similarity(wn.synset('woman.n.01')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this, our decision is now between **Path Similarity** and the **Lin Similarity**. As we can see from the combined analysis of the sum of values and the difference between local maximums and minimums, **Lin gives more accurate scores**, yielding **higher numbers in the overall matrix (total sum: 14.464)** and having a **greater difference between the similar and non-similar words (0.574)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Over the development of this lab, we have calculated the most frequent WordeNet synsets and their least common subsumers. We have also analyzed their similarity value according to 4 different algorithms and have appllied normalization when needed. \n",
    "\n",
    "Another thing to highlight is that the HiddenMarkovModel looks really efficient timewise. It is likely that its just not in the desired set of conditions regarding the amount of data to perform correctly. \n",
    "\n",
    "Based on our analysis, we have selected the **Lin-Similarity as the best performing algorithm**. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
